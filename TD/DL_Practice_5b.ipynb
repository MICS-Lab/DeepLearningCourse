{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "ovDJUER3rFK4"
   },
   "source": [
    "# TD 5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "wdmJfTThvBnc"
   },
   "source": [
    "[Use PyTorch for all questions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "R9k-Z90ivZfW"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\__APP__\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "import time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Width vs Depth"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal here is to compare the performances of basic networks.\n",
    "We will create both very wide and very deep networks, and see which ones are better."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will try to fit a sequence of functions with increasing complexity, both with a wide and with a deep network.\n",
    "The first part concentrates on the minimal amount of neurons needed to fit the function with an optimal network (setting the weights and biases manually).\n",
    "Then, the second part studies the training of the same networks, to fit the same functions. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Theory"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking the function of interest: $f: \\mathbb{R} \\to \\mathbb{R}$ to be linear by segment, with 4 segments:\n",
    "- $f(x) = 0$ on $\\left] -\\infty, 0 \\right]$\n",
    "- $f(x) = 2x$ on $\\left] 0, \\frac{1}{2} \\right]$\n",
    "- $f(x) = 2-2x$ on $\\left] \\frac{1}{2}, 1 \\right]$\n",
    "- $f(x) = 0$ on $\\left] 1, \\infty \\right]$\n",
    "\n",
    "Define $f : x\\: \\rightarrow f(x)$ as a python function, using numpy.\n",
    "\n",
    "Let also:\n",
    "- $g(x, 2) = f \\circ f(x)$\n",
    "- $g(x, 3) = f \\circ f \\circ f(x)$\n",
    "- $g(x, 4) = f \\circ f \\circ f \\circ f(x)$\n",
    "- etc...\n",
    "\n",
    "Define $g : x\\: \\rightarrow g(x, l)$ as a python function for all $l \\in \\mathbb{N}^*$.\n",
    "\n",
    "Plot $f$ and $g$ on $\\left] -0.2, 1.2 \\right]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a basic \"rectange\" network class (width is the same in all hidden layers);\n",
    "leave the number of layers and number of neurons per layer as parameters, and use ReLU activation function.\n",
    "The input and output are 1D, since we fit functions $\\mathbb{R} \\to \\mathbb{R}$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With 4 hidden layers and 5 neurons per layer, your network class should create a network as follows:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/rectangle_network.svg\" alt=\"rectangle network diagram\" style=\"width: 35em;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement $f$ with a (basic) rectangle network with 1 hidden layer of 3 neurons.\n",
    "Set the weights youself to fit exactly the function.\n",
    "\n",
    "*Hint:*\n",
    "$f(x) = 2x_+ -4(x-\\frac{1}{2})_+ +2(x-1)_+$\n",
    "$\\qquad \\qquad$ (where $\\alpha_+$ is $ReLU(\\alpha)$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, implement $g$ for `level = 4`, by increasing the width (and keeping a single hidden layer).\n",
    "Use again a rectangle network and set the weights youself.\n",
    "\n",
    "*Hint: try to find the weight for `level = 2`, then `level = 3`, and deduce the pattern.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many neurons did you need in the hidden layer? How will that evolve when the level increase?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need $2^{level}+1$ neurons, this increases exponentially with `level`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, implement $g$ for `level = 4`, by increasing the depth (and keeping 3 neuron per hidden layer).\n",
    "Again use a rectangle network and set the weights youself.\n",
    "\n",
    "*Hint: try to find the weight for `level = 2`, then `level = 3`, and deduce the pattern.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many neurons did you need in the hidden layer? How will that evolve when the level increase?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need $3*{level}$ neurons, this increases linearly with `level`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a semilogy, plot the number of neurons used to replicate $g$ as a function of `level` (ranging from 1 to 15), by increasing the width and the depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a semilogy, plot the number of parameters used to replicate $g$ as a function of `level` (ranging from 1 to 15), by increasing the width and the depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will try to fit `g` with `level = 4` both with deep and wide networks; This time, by training the network, instead of manually setting the weights."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, train a wide network, of course, it will need more neurons than the mathematically optimal solutions.\n",
    "Try with 5 times more neurons than in the optimal solution, and about $15000$ epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Convergence is not reached, but given a little more time, it should converge nicely towards the solution.*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, train a deep network, again, give a little slack on the number of neurons compared to the optimal solution.\n",
    "Try with 10 times more layers than necessart, and 15 neurons per layer instead of 3, and about $5000$ epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- *See that the training takes much more time than with the wide network, despite the fact that we have less epochs.*\n",
    "- *Observe also that there is no sign of convergence; Try to explain this.*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:**\n",
    "\n",
    "The number of neurons is a good measure of the size (in terms of memory) of your network;\n",
    "For the same amount of neurons, deep networks, can catch more complexity, but are harder to train.\n",
    "On the contrary, wide networks catch less complexity, but are easier to train.\n",
    "\n",
    "*Your goal as an AI engineer is to find the best architectures, so that your networks are both trainable and able to catch the complexity of the observed phenomenon.*"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "a61f982c8ae83496d3304782998ac96a47f5fcf9bfc174247e19a8162c5490e4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
