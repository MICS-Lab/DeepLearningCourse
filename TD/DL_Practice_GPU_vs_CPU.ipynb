{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CPU vs GPU in practice"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.42 µs ± 46.5 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "z = torch.randn(1, 1)\n",
    "result = torch.matmul(z, z)\n",
    "del z\n",
    "del result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.7 ms ± 708 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "z = torch.randn(1_000, 1_000)\n",
    "result = torch.matmul(z, z)\n",
    "del z\n",
    "del result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.2 s ± 201 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "z = torch.randn(10_000, 10_000)\n",
    "result = torch.matmul(z, z)\n",
    "del z\n",
    "del result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66.5 µs ± 7.14 µs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "z = torch.randn(1, 1).to(device)\n",
    "result = torch.matmul(z, z)\n",
    "del z\n",
    "del result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.56 ms ± 48.5 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "z = torch.randn(1_000, 1_000).to(device)\n",
    "result = torch.matmul(z, z)\n",
    "del z\n",
    "del result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576 ms ± 63.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "z = torch.randn(10_000, 10_000).to(device)\n",
    "result = torch.matmul(z, z)\n",
    "del z\n",
    "del result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "\n",
    "- $1$ x $1$ -> $4.42$ µs vs $66.5$ µs.\n",
    "\n",
    "CPU is **15x** faster than GPU.\n",
    "\n",
    "- $1,000$ x $1,000$ -> $20.7$ ms vs $5.56$ ms.\n",
    "\n",
    "GPU is **3.7x** faster than CPU.\n",
    "\n",
    "- $10,000$ x $10,000$ -> $11.2$ s vs $576$ ms.\n",
    "\n",
    "GPU is **19.4x** faster than CPU.\n",
    "\n",
    "This WILL depend on your hardware, but in general, GPUs are much faster than CPUs for large matrix multiplication."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL_NLP_2022-2023",
   "language": "python",
   "name": "dl_nlp_2022-2023"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "a61f982c8ae83496d3304782998ac96a47f5fcf9bfc174247e19a8162c5490e4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
