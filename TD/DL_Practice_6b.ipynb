{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "ovDJUER3rFK4"
   },
   "source": [
    "# TD 6"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "wdmJfTThvBnc"
   },
   "source": [
    "[Use PyTorch for all questions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "R9k-Z90ivZfW"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\__APP__\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN: Determinating Lastnames Origins"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal here is to build our first (basic) RNN network."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a datset composed of 18,000 names, from 18 nationalities (1,000 names from each country).\n",
    "We try to build a network to classify names to their correct nationality.\n",
    "We do that with a RNN, that \"reads\" each letter one by one."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link to the dataset `name_1000`, containing 1,000 names from 18 nationalities:\n",
    "https://drive.google.com/drive/folders/1qqyB_ZRMsz_7veqlKYnJH2kmYK6myV4Y?usp=share_link\n",
    "\n",
    "Start by downloading it and store it in your working directory.\n",
    "\n",
    "As we haven't dealt with unbalanced datasets yet, all 18 nationalities are represented with the same number of names. This is not the case in real life and wasn't the case initially. Even though we will ignore this for now, you need to keep in mind that because the dataset was smaller from some nationalities, you can see that in `Vietnamese.txt`, some names appear several times. This will be a problem theorethically, as when we split the dataset into `train` and `test`, we will have some names in the `test` set that were already in the `train` set. The point though is not to commercialize this model, but to learn how to build a RNN (question: can you remind us what's the problem RNNs try to solve?). So we will ignore this."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some countries are using non-latin alphabet, we need the ASCII version.\n",
    "You can try the function `unidecode` from the `unidecode` mdule.\n",
    "\n",
    "Create a function that takes a name, and return its version using only letters from \n",
    "`LETTERS = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ .,;'` (you can add some letters if you want, but the more you add, the more complex your network will become)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your function on `'Ślusàrski'`, `'François'`, `'北亰'`, `'Kožušček'`, and `'+-*/'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feeding letters to a network"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A network can not, originally, process characters/letters; networks can only understand numbers, and list of numbers.\n",
    "We need to turn our characters to a vector. We could just take the binary byte representing the character in the ASCII. However, this would be very hard for the network to understand (`x: 1011000`, `y:1011001` and `z: 1011010` will have very similar activations).\n",
    "Thus, we will use 'one-hot encoding' of our set of letters `LETTERS`. That is, we transform each letter to a tensor of size `<1xN_LETTERS>`, where all entries are zero except the one corresponding to the position of the letter, that we set to one.\n",
    "e.g.:\n",
    "- `a => [1, 0, 0, 0, ..., 0]`\n",
    "- `b => [0, 1, 0, 0, ..., 0]`\n",
    "- `c => [0, 0, 1, 0, ..., 0]`\n",
    "\n",
    "Define a `letterToTensor` function that perfoms this operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now define a `nameToTensor` function that perfoms this operation for each letter in the name (resulting to a `<name_length x 1 x N_LETTERS>` tensor)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a custom dataset:\n",
    "- in the `__init__`, read all files, and create a list of names and associated country\n",
    "- add a `countryID` method that turns a country its index\n",
    "- add a `countryTensor` method that turns a country to a one-hot encoded tensor\n",
    "- the `__getitem__` should return one piece of data in the form `(name, country, nameTensor, countryID)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dataloader for the dataset; the `batch_size` must be 1, since different names can have different lengths (and therefore, different tensor size)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the RNN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the RNN with the following parameters:\n",
    "- `input_size`: number of input features\n",
    "- `hidden_size`: number of hidden units\n",
    "- `output_size`: number of output features\n",
    "- `idx_to_country`: list of countries\n",
    "\n",
    "The input is a one-hot vector of size `N_LETTERS`; the output is a one-hot vector of size `N_COUNTRIES = len(idx_to_country)` + a hidden state of size `hidden_size`.\n",
    "You can build the architecture you like, but one that is known to work is the [following](https://i.imgur.com/AJHiuhO.png)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is, a simple dense layer that takes as input the concatenation of the hiden state and the current letter, and outputs both the new hidden state and a vector of likelyhood for each country. Adding a softmax layer to the countries likelyhood turns them to actual probabilities."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On top of the `__init__` and `forward` methods, define:\n",
    "- `init_hidden` a method that creates a zero hidden state (that we will use as a hidden state when sending the first letter)\n",
    "- `outputToCountry` to convert output probabilities to the corresponding country\n",
    "- `outputToID` to convert output probabilities to the corresponding country ID"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a network with 128 hidden units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feeding the RNN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feed a single letter to the network (i.e. 1 step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feed a full word to the network (i.e. multiple steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the network"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the network; for each iteration of the training:\n",
    "- Create a zero initial hidden state\n",
    "- Feed each letter in and keep hidden state for next letter\n",
    "- Compute the loss\n",
    "- Back-propagate\n",
    "- Zero-out the gradients\n",
    "\n",
    "One configuration that is known to work (for the architecture described above):\n",
    "- Optimizer: Adam\n",
    "- Learning rate: `lr = 0.001`\n",
    "- Loss: Negative log likelihood (`NLLLoss`)\n",
    "- Epoch: No need for too many epochs (~5-10 is enough)\n",
    "\n",
    "NB: if you did not put a softmax, use `CrossEntropyLoss` instead of `NLLLoss`.\n",
    "\n",
    "*(Training takes ~3min on a modern laptop.)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the network"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing should be done on a different dataset than training !!!**\n",
    "Here we use the same dataset for simplicity."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test on a couple of names from the dataset, display the name, the prediction, and the ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test on the full dataset:\n",
    "- Plot the confusion matrix\n",
    "- Compute the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy on the dataset is ~60%; this is much better than taking a random guess (which would have an accuracy of ~5.5%).\n",
    "\n",
    "You can do you own experiences to improve this result (add layers, test other layers such as LSTM or GRU, try some combinations).\n",
    "\n",
    "You can also change dataset (eg: word -> language; name -> gender; title -> newspaper; etc...)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This RNN exercise was inspired from a notebook from [the official PyTorch documentation](https://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7 (tags/v3.10.7:6cc6b13, Sep  5 2022, 14:08:36) [MSC v.1933 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "689ffbb94fe8f58a5045b4f3f0726e738a118a8a590ae859861904a2cad8ac3d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
